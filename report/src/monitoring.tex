\chapter{Monitoring}
	Dans cette partie nous étudierons en détails le fonctionnement des techniques principales de mesures existantes. Premièrement nous présenterons les deux techniques en elle-même et expliquerons leur fonctionnement interne, ensuite nous évoqueront les points forts et points faibles de chacune, puis nous parlerons des mécanismes metériel et système qui se chargent de leur mise en fonctionnement. Enfin la dernière partie discutera de techniques nouvelles et plus poussées existantes.
	\section{Introduction}
		Le monitoring est le fait de suivre l'éxécution d'un programme pour savoir quelles sont les ressources utilisées par une certaine entité. Le monitoring permet de connaître les ressources qu'utilise un système de sorte à ce que l'éxécution d'un programme puisse être optimisée et se dérouler de manière plus performante. Il existe deux manières principales de faire du monitoring : 
		\benum
			\item{Choisir un type d'évènements à compter, chaque évènement qui occure va incrémenter un compteur d'évènement qui sera ensuité récolté}
			\item{Executer le suivi d'un instruction précise et repertorier les effets que cette instruction incombe sur le système}
		\eenum
		Grâce au monitoring nous pouvons connaître les effets précis d'un programme sur le systeme, les évènement généralement intéréssants à surveiller sont les suivants :
		\benum
			\item{Fautes de cache}
			\item{Etat de branchement d'une instruction}
			\item{Entrées/Sorties provoquées par une instruction}
		\eenum
		Les processeurs récents mettent à disposition des outils qui permettent d'effectuer des mesures sur les instructions qu'ils effectuent. Ces outils sont des programmes miniatures, implantés en dur sur le processeur, et utilisent pour leur éxécution des registres dédiés à cette utilisation. Par conséquent, nous allons devoir agir sur ces registres dédiés, certains dans lesquels nous allons lire pour récupérer les informations qui nous seront nécéssaires, d'autres dont il faudra modifier les valeurs pour mettre en place les mesures. Les registres utilisés ici sont de type Model Spécific Register (MSR), ils vont donc permettre l'interaction entre le système d'exploitation et le materiel. Les MSR sont donc spécifiques à chaque architecture et peuvent être liés à des fonctionnalités de debuggage, de monitoring, mais le système peut également s'en servir pour activer des fonctionnalités du processeur, donner des informations de temps (cycles CPU, timestamp counter), et peuvent être utilisés pour de la gestion d'erreur. AMD sur ses processeurs fournit 2 types de MSR : 
		\benum
			\item{MSR Legacy : un pannel de registres communs à tous les modèles de processeurs, permet de définir une norme}
			\item{Les autres MSR : qui sont eux, spécifiques à chaque modèle de processeur}
		\eenum
	\section{Outils de monitoring étudiés}
	\subsection{Performance Monitoring Counters}
		Le procédé Performance Monitoring Counters utilise des MSR Legacy et est donc implanté sur la plupart des modèles de processeurs. C'est un type de monitoring où l'on mesure la fréquence d'apparition de certains évènements prédéfinis de base dans la documentation du processeur. Lorsqu'un évènement mesuré se produit, le compteur qui lui est associé est incrémenté. Par conséquent, régulièrement, le processeur lève une interruption et une fonction définie au préalable va s'occuper de venir récupérer les valeurs enregisrées dans ces registres. D'autre part, les Performance Monitoring Counter engendrent certains problèmes de cohérence lorsqu'ils sont mis en ouvre sur des processeurs multi-coeur, décrit plus bas. (cf. : Challenges du monitoring)
		\paragraph{Implémentation}
			L'architecture Legacy pour la mise en place des \PMC met à disposition 4 MSR pour le contrôle des evenements et respectivement le même nombre de registres pour le résultat. Il existe pour certains types des processeurs des extensions permettant des mesures plus poussées, en rapport avec le NorthBridge. Chaque MSR contrôle un évènement distinct et lorsque l'évènement se produit, le registre associé est incrémenté. Le traitement à effectuer dans la fonction de traitement (handler) est donc de récupérer l'information stockée dans le MSR voulu et le remettre à 0 afin de ne pas fausser les mesures suivantes.
	\subsection{Instruction Based Sampling}
		Une deuxième méthode de monitoring existe sur les architectures AMD récentes. C'est une technique de profiling spécifique à AMD et ses processeurs, qui l'a introduit à partir des familles AMD 10th Family. Elle permet de corriger certains défauts de la méthode de profiling \PMC. Le principe de cètte technique est d'effectuer le suivi d'une instruction pendant son éxécution. Durant le fil d'éxécution d'un processeur, IBS va tagger une instruction choisie aléatoirement et va procéder au suivi. Les instructions des set d'instructions des proceseurs AMD sont complexes et de taille variable, ces instructions ne sont pas directement éxécutées par le processeur, elles sont décomposées en plusieurs instructions de plus petite taille, les macro-ops qui sont elles, de taille fixe. L'ordonnanceur du processeur découpe ensuite ces macro-ops en des micro-ops. Chaque micro-op est de taille fixe et représente une opération primaire d'arithmétique ou une opération de mémoire tel qu'un Load ou un Store. Ce sont donc les micro-op qu'IBS va tagger et surveiller. IBS, de notre point de vue, représente plus d'avantages que d'inconvénients, nous avons donc choisi cette technique de profiling dans le cadre de notre projet.
		\subsubsection{Implémentation}
			La majeure patie de l'interaction que le système peut avoir avec les mesures IBS se fait par le biais de MSR, qui ne sont pas des MSR Legacy car spécifiques aux processeurs AMD. AMD offre 2 façons d'effectuer de la surveillance sur une instruction : IBS Fetch Sampling et IBS Execution Sampling. Chacune de ces deux méthodes effectue des analyses des effets rétro-actifs sur le système d'une instruction. \\
			Une opérations est taggée pendant le travail du processeur sur un intervalle de temps configurable. Cet intervalle est mis en \oe uvre grâce à un compteur qui va être incrémenté régulièrement. Lorsque ce compteur atteint un seuil configurable, une interruption est soulevée et prévient le système que l'analyse est terminée, il doit alors venir récolter les informations contenues dans les registres. Ensuite le compteur sera remis à 0 et une nouvelle instruction sera taggée pour être surveillée. L'incrémentation du compteur peut se faire de 2 façons : 
			\bitem
				\item{A chaque cycle d'horloge}
				\item{A chaque instruction éxécutée par le processeur}
			\eitem

			\paragraph{IBS Fetch Sampling}
			La première méthode consiste à donner des informations sur la partie "Fetch" de l'éxécution d'une instruction. Le Fetch est la suite d'opérations qu'effectue un processeur avant d'éxécuter une opération. Il va s'occuper de charger l'instruction suivante en mémoire, il remplit le registre d'instructions pour le prochain cycle, et par conséquent met à jour la TLB d'instruction du processeur (ceci fait partie du cycle déxécution d'une instruction, Fetch / Décode / Memory / Execute). Le IBS Fetch Sampling va donc nous donner des informations sur le déroulement du Fetch de l'opération taggée. Principalement, les informations utiles concernant la TLB d'instructions (hit / miss / latence). Pour utiliser IBS Fetch Sampling nous allons prendre en compte 3 registres, 1 registre de contrôle et 2 registres contenant des adresses et physiques. Le registre de contrôle va permettre de lancer les mesures (mettre à jour le bit IBSFetchEnable) et de récolter les résultats, après que les mesures aient été efectuées. Les informations contenues dans ce registre peuvent nous indiquer si l'instruction surveillée a causé un MISS dans la TLB d'instructions, ainsi que la latence du cycle de Fetch.\\
			\paragraph{IBS Execution Sampling}
			Lorsque l'on veut avoir des analyses plus détaillées sur l'éxécution de l'opération, on utilise la deuxième méthode qui est IBS Execution Sampling. 			Le but principal d'IBS Execution Sampling est de fournir des informations de manipulation de mémoire que pourrait effectuer l'instruction si l'instruction est de type Load ou Store. Il va donc nous indiquer si cette opération a causé une faute de cache (L1 ou L2), si elle a causé une faute de cache sur la TLB, des informations sur les controlleurs d'entrées/sorties qui ont étés impliqués dans le traitement de l'instruction, des informations d'état général de la DRAM. Pour une opération de mémoire nous allons pouvoir également récupérer les adresse physiques et linéraires qui ont été utilisées. IBS va aussi fournir, si l'instruction surveillée n'est pas une opération de mémoire mais un branchement, si ce branchement a été pris ou non ainsi que les adresses de destination et d'origine du branchement. La configuration des mesures se fait via le MSR IbsOpCtl, dans lequel en activant le bit IbsOpCtlEn va entamer les mesures. La fréquence d'échantillonage est aussi configurable au travers de ce MSR. 
			\paragraph{Traitement des résultats}
				Les résultats produits après le soulevement d'une interruption de fin de mesures vont être répartis dans différents MSR : 
				\bitem
					\item{MSR\_IBSOPDATA1 : Ce registre va contenir des informations si l'opération taggée est un branchement, les informations concernant le résultat du branchement.}
					\item{MSR\_IBSOPDATA3 : Ce registre contient toutes les informations les plus importantes si l'opération taggée etait un Load ou un Store. Les informations retournées sont : la donnée a-t-elle fait une faute de cache des données, si l'accès à la donnée a eu pour conséquence un bloquage du processus, si cette donnée a-t-elle provoqué une faute de cache de la TLB, si cette instruction a voulu accéder à de la mémoire inatteignable, et la latence entre une faute de cache (L1 ou L2) et l'arrivée de la donnée au processeur.}
					\item{MSR\_IBSOPDATA2 : Les informations contenues dans ce regsitres soont spécifiques à chaque architectures. Pour notre modèle et notre architecture, à l'issu d'une mesure, ce registre contient des informations sur l'état de la donnée dans le cache L3, les 8 derniers bits spécifient l'emplacement de la donnée si elle ne se trouvait pas dans le cache L3, en passant par le NorthBridge (DRAM, MMIO, périphérique PCI etc...). Ce registre ici nous informe si la donnée se trouvait sur un n\oe ud autre que le notre.}
					\item{MSR\_IBSOPRIP : le contenu du registre d'instructions lors de l'éxécution de l'opération.}
					\item{MSR\_IBSDCPHYSAD et MSR\_IBSDCLINAD : les adresses virtuelles et physiques de la donnée accédée.}
					\item{MSR\_IBSBRTARGET : l'adresse de la cible du branchement si l'opération qui a été taggée etait un branchement}
				\eitem
			\section{Avantages et inconvénients des methodes de monitoring existantes}
				\subsection{Inconvénients des \PMC}
					L'usage de \PMC est une pratique assez commune et utilisée par beaucoup de profiler actuels, cependant celle-ci comporte son lot de bogues et de limitations que le programmeur doit être préparé à prendre en compte pour juger de l'exactitude des mesures :
					\subsubsection{SKID}
						Les processeurs actuels sont capables d'éxécuter plusieurs instructions à la fois et par forcément dans l'ordre dans lequel elles été destinées à etre éxécutées, par conséquent cette situation entraine des erreurs de précision lors de l'utilisation des \PMC pour surveiller les actions d'un processeur. En effet, lorsque le processeur enregistre l'adresse d'une instruction qui a causé un évènement mesuré grace à \PMC, il est possible que le processeur aie effectué plusieurs instructions en parallèle. Il y a donc un décalage possible au niveau des instructions surveillées. Cette écart sur les processeurs AMD est de +/- 2 instructions. Ce problème peut ne pas être grave si l'on souhaite surveiller les effets d'une fonction sur le système et non pas une instruction precise, car à cause des effets de ce que l'on appelle la localité spatiale, il y a une forte chance qu'une instruction mesurée à proximité d'une fonction, fasse partie de la fonction. Nous étudierons plus loin, comment palier à ce problème grâce aux IBS.
					\subsubsection{Dépassement de comptage d'accès mémoire}
						De nombreuses technologies apparues sur les processeurs récents permettent d'améliorer l'efficacité et la vivacité d'un processeur. Cependant, ces technologies rendent la vie dure aux instruments de surveillance comme les \PMC car ceux-ci ne peuvent pas s'adapter aux améliorations de chaque constructeur. Nous allons donc étudier certaines d'entre elles et les problèmes qu'elles engendrent : 
						\bitem
							\item{Prefetcher : le prefetcher incluant des accès mémoire supplémentaires pour ramener des données en mémoire avant qu'elles ne soient demandées, provoque une nombre d'accès mémoire supérieur au nombre réel d'accès effectué par une instruction, cela implique des incohérences et des résultats pas complètement fiables quant-à l'éxécution d'une fonction. Malheureusement les mécanismes de prefetcher etant spécifiques à chaque architecture de processeur, il est difficile de prévoir les effets que cela pourrait produire.}
							\item{HT Assist : Cette technologie d'AMD permet de limiter le surcoût du maintient de cohérence des caches processeurs pour les système à plusieurs processeurs. En effet à chaque accès à une donnée, un processeur doit être sûr qu'il accède à la dernière version de cette donnée. Il envoie donc, à chaque accès à une donnée en cache, des demandes à tous les autres processeurs pour savoir si la donnée à été modifiée par quelqu'un. Cela augmente donc grandement le temps d'accès à une donnée en cache. La technologie HT Assist permet de réduire ce nombre de requêtes aux autres processeurs, il réserve une partie du cache L3 pour stocker une liste, pour chaque ligne de cache, des différents processeurs qui possèdent la donnée. Ainsi lorsque le processeur va vouloir mettre à jour une donnée avant d'en utiliser le contenu, il saura où se trouve cette donnée et à qui la demander. Cette technique de cohérence de cache implique dans le cadre de mesures, des accès mémoire supplémentaire au cache L3 auxquels il faut être conscient lorsque l'on effectue les mesures. Il est cependant possible de désactiver cette fonction sur le processeur.} 
						\eitem
					\subsubsection{Localisation du comptage}
						\PMC est une technique de profiling qui a ses limitations si l'on veut surveiller le déroulement d'une fonction précise sur le code source. De fait par sa construction, il est assez utile pour donner une vue d'ensemble d'un processeur durant un certain interval de temps mais lorsqu'il s'agit de surveiller les effets d'une fonction particulière, cela n'est pas possible. Les \PMC ne pourront qu'indiquer quelle est le nombre d'évènement apparus, mais pas leur localisation. Pouvoir cibler exactement une portion de code pour l'étudier est pourtant d'une grande utilité pour un programmeur.
					\subsubsection{Décalage entre temps des mesures et temps de récupération des données}
						Comme expliqué plus tôt, lorsqu'un compteur dépasse un seuil configuré auparavant cela provoque une interruption, et c'est ensuite au noyau de traiter cette interruption grâce à une fonciton. Cette fonction va alors récupérer les comptes contenus dans les registres. Les interruptions materielles étant nombreuses (principalement l'interruption horloge), il est possible que le temps que le noyau en vienne à éxécuter le code de la fonction, les valeurs qui été présentes dans les registres lors de l'interruption ne soient plus les mêmes et que des évènements soient compté en trop.
					\subsubsection{Surestimation}
						\PMC donne la possibilité de compter le nombre d'instructions éxécutées pendant un interval de temps. Cependant il se peut que l'on observe une surestimation du nombre d'instructions comptées pour plusieurs raisons : 
						\bitem
							\item{Les instructions découpées en macro-ops puis en micro-ops peuvent causer une incohérence du compte réel, le problème est que la méthode de découpage est très peu documenté sur les processeurs, indeterministe et spécifique à chaque modèle.}
							\item{Les jeux d'instructions de type SSE incluent aussi des cohérences vis-à-vis du nombre d'opérations comptées.}
							\item{Des interruptions imprévisibles et indeterministes émergent fréquemment dans un système et induisent leur lot d'operations supplémentaires.}
						\eitem
				\subsection{IBS}
					\IBS est une méthode de profiling assez différente des \PMC, spécifique aux processeurs AMD, elle est moins utilisée que les \PMC dans les profilers les plus communs car plus récente et plus complexe à mettre en place. Par ailleurs, cette technologie permet de contourner quelques uns des défauts les plus handicapant des \PMC. Cependant, comme toute technologie, elle admet quelques points négatifs.
					\subsubsection{Aléatoire des mesures}
						Bien qu'il soit possible de définir un minuteur pour le choix régulier des instructions à surveiller, lorsque l'intervalle est passé, le choix se fait aléatoirement sur un pannel d'instructions. D'une part à cause de l'éxécution multiple d'instructions sur un processeur (présentées précédemment), d'autre part à cause du découpage indéterministe des instructions en micro-ops et leur éxécution non ordonnée. La vision d'AMD pour l'utilisation d'\IBS est donc de fournir des informations précises à un moment donné, mais en contrepartie de fournir la cible qu'elle a choisi pour récolter ses informations, de manière à ce que le traitement soit plus clair.
					\subsubsection{Travail en arrière-plan}
						Un autre défaut de la méthode de profiling \IBS est que celle-ci ne permet pas de surveiller le travail fait en arrière-plan par, par exemple, le prefetcher ou le HT Assist. Cela peut s'avérer handicapant si l'on veut effectuer des mesures poussées.
					\subsubsection{Overhead}
						L'utilisation d'\IBS implique des traitements supplémentaires pour chaque instructions taggées. Cela provoque alors un ralentissement notable des performances du système. Cette augmentation de traitement est directement liée au taux d'echantillonnage que l'on configure. Malheureusement, lorsque l'on veut étudier un effet se produisant peu frequemment sur le système (rapatrier une donnée à partir d'un cache distant), il va falloir augmenter le taux d'échantillonnage de sorte à ce que la probabilité de tagger une instruction qui provoque ce mécanisme soit plus importante et lorsque l'on augmente le taux d'échantillonnage, l'overhead devient considérablement grand, ainsi que la latence du système.
			\section{Mise en \oe uvre}
				\subsection{Introduction}
					De sorte à mettre en oeuvre les mesures, nous avons du chercher, et trouver les outils qui nous permettent au niveau de materiel ainsi qu'au niveau du noyau, de gérer principalement les interuptions qui sont soulevées par \IBS lors de la fin d'un cycle de mesures. Nous allons donc dans cette partie, expliquer comment ces interruptions sont soulevées et centralisées au niveau du processeur (APIC) et également comment faire le lien entre ces interruptions et le noyau Linux (NMI).
				\subsection{Advanced Programmable Interrupt Controller}
					\subsubsection{Introcuction}
						La plupart des périphériques d'entrée/sortie ont régulièrement besoin de notifier le processeur, pour que celui-ci effectue un traitement particulier. Pour ce-faire un périphérique doit faire appel au processeur par le biais de signaux envoyés que l'on appelle interruptions. Par ailleurs, les périphériques étant nombreux dans le système, le processeur ne peut pas traiter simultanément toutes les interruptions soulevées par le materiel. Il existe donc une puce implantée directement dans le processeur, appelée controlleur, qui va se charger de faire le lien entre une interruption soumise pour un traitement (Interrupt ReQuest, IRQ) et le processeur. De cette façon, le processeur est déchargé de cette tâche de gestion des interruptions.\\ 
					Sur les processeurs d'architecture x86 actuels, l'Advanced Programmable Interrupt Controller (APIC) est découpé en 2 parties, le Local APIC, et le IO-APIC. 
					\subsubsection{Local APIC}
						Le Local APIC la partie qui nous interesse pour faire fonctionner les mesures, chaque coeur sur les processeurs multi-coeurs possède son propre Local APIC. Le \lap est donc directement cablé au processeur et les \lap de chaque processeurs sont interconnectés et peuvent donc communiquer entre eux par le biais d'interruptions inter-processeur (IPI). Ces IPI peuvent engendrer des actions entre les coeurs tel que des purges de mémoire, des purges de TLB, etc... Ce \lap va donc recevoir les interruptions qui surviennent sur le système, va leur donner une priorité et ensuite va les délivrer par l'ordre de priorité donnée, chacune séparée par un signal End Of Interuption (EOI). \\
					Lorsque le processeur reçoit une interruption, il stoppe l'éxécution de l'opération en cours, sauvegarde son contexte d'éxécution, et effectue la suite d'instruction qui correspond au traitement de l'interruption (handler). Dans notre cas, lors de la phase d'initialisation des mesures, nous allons devoir programmer le \lap pour que celui-ci prenne en compte les interruptions retournées par les \IBS en fin de cycle de mesures. Cela se fait par le biais de la fonction apic\_write(). Cette initialisation va donc devoir être faite auprès des \lap de chaque coeur.\\
					\subsubsection{IO-APIC}
						La deuxième partie de l'APIC, nommée IO-APIC, est un controlleur d'interruption intégré également au système, qui va se charger de re-diriger toutes les interruptions provenant des périphériques externes d'entrée/sortie, vers le \lap. Les périphériques d'entrée/sortie ne font alors appel qu'à ce seul controlleur. Il ne sera pas nécéssaire de faire appel à ce controlleur dans le cadre de notre projet.
				\subsection{Enregistrer un handler NMI}
					\subsubsection{Introduction}
						Le programme d'\IBS d'AMD fournit une gestion de compteurs, et lorsque ces compteurs atteignent un seuil, il génèrent une interruption. Au niveau du noyau, cette interruption doit être traitée grâce à un handler, une fonction qui va se charger d'aller récupérer les valeurs écrites par le matériel dans les registres correspondant. Cette fonction de traitement doit etre déclarée au niveau de l'APIC pour que celui y fasse appel au moment voulu.
					\subsubsection{Interruption non-masquables (NMI)}
						Les interruptions générées par \IBS sont des instructions de type Non Maskable Interruption (NMI). Le but architectural des NMI est de servir de "meta-interruption" pour le système, c'est-à-dire, des interruptions qui peuvent interrompre elles-même les handler d'interruption. Non masquables signifient que ces interruptions ne peuvent pas être mises en attente d'être traitées, elles sont traitées immédiatement. Physiquement les NMI sont cablées sur des broches dédiées du processeur, de sorte à les différencier des autres IRQ. On décèle 2 principales utilisations des NMI, la premiere est pour le profiling. En effet, les NMI permettent d'interrompre n'importe quelle interruptions, permettant au profiler de surveiller l'éxécution des interruptions elles-mêmes. Cela permet de connaître en détails les effets d'un handler sur le système et de les mesurer comme tout autre fonction.\\
						L'autre principale utilité des NMI concerne la reprise d'activité suite à des arrêts du noyau, des erreurs qui mettraient le noyau dans un état d'interblocage et où l'on ne pourrait pas reprendre la main. Pour palier à ce problème, les noyaux Linux ont mis en place un programme de surveillance (Watchdog) basé sur les NMI. Si activé, le programme de Watchdog NMI va périodiquement aller incrémenter des variables du noyau, ce programme va s'éxécuter sur chaque coeur du système et incrémenter la variable correspondant au coeur courant. Ensuite, sur un intervalle de temps régulier, un handler de NMI va aller vérifier que ces compteurs ont été incrémentés depuis la dernière vérification. Ainsi, si le noyau est bloqué, ou qu'un coeur est bloqué, ce compteur ne sera pas mis à jour et le handler NMI qui va le constater pourra détécter la panne. La configuration actuelle du NMI Watchdog défini une limite de temps de 5 secondes pour une entité bloquée, avant de lancer une procédure de redémarrage.\\
						Dans le cadre de notre projet, pour l'initialisation il sera donc nécéssaire de stipuler au \lap que nous allons utiliser des interruptions non-masquables, ainsi que d'enregistrer notre handler pour le traitement d'une interruption générée par \IBS.
				\subsection{Kthreads}
					\subsubsection{Introduction}
						L'un des challenges rencontrés lors de la mise en \oe uvre du module noyau de mesures que nous avons développé, était que nous allons ecrire un module qui serait intégré au code même du noyau, donc faire en sorte que si ce module plante, le noyau n'en soit pas affecté. Pour cela nous avons plutôt qu'utiliser les fonctions d'insertions et suppression de module pour lancer nos mesures, appelé à l'utilisation de threads noyau. Seulement cela incombe quelques difficultés qu'il faut prendre en compte.
					\subsubsection{Thread noyau}
						Un thread noyau est l'équivalent logique d'un thread utilisateur, le thread noyau ayant lui accès à toute la mémoire car éxecuté en mode noyau, et plus prioritaire du point de vue ordonnancement qu'un thread utilisateur. Pour faire en sorte que celui-ci, s'il plante, effectue des traitements trop long, ou des boucles infinies n'affecte pas le noyau nous avons joué sur plusieurs principes : 
						\bitem
							\item{Un thread noyau lancé n'est initialement pas interruptible par un signal. Il faut donc spécifier par l'appel d'une fonction noyau, que ce thread peut recevoir des signaux, cette fonction va modifier le champ correspondant dans la task\_struct de notre thread.}
							\item{Explicitement donner la liste des signaux qui peuvent venir intéragir avec le thread concerné, un signal de terminaison (SIGTERM), de terminaison forcée (SIGKILL), de suspension (SIGSTOP), etc...}
							\item{Il existe deux façons pour un thread noyau de se terminer proprement :
								\bitem
									\item{Si celui-ci effectue un traitement ponctuel, et qu'ensuite il doit se terminer, appeler seulement à \emph{return} ne suffit pas à l'arreter proprement, pour ce-faire le thread doit appeler à la fonction \emph{do\_exit()} avant d'effectuer un \emph{return}.}
									\item{Un thread qui doit effectuer un traitement constant et régulièrement pour une durée indeterminée et donc qui doit être arrété par un autre thread, n'a pas d'autre possibilité que de se répéter en testant la condition \emph{kthread\_should\_stop()}. Ainsi un autre thread appelera la fonction \emph{kthread\_stop()} et la condition de sortie du premier thread sera validée, il se terminera proprement.}
									\item{Attention : l'utilisation de \emph{kthread\_should\_stop()} implique qu'un thread ne doit pas appeler la fonction \emph{do\_exit()} pour se terminer.}
								\eitem 
							}
							\item{Priorité d'execution : un thread noyau à sa création va acquérir un haut niveau de priorité, il se peut que cela soit la cause d'un ralentissement général du noyau, car ce thread ne laissera pas assez de temps aux autres fonctions du noyau pour s'éxécuter. Pour éviter ce genre de problèmes, il faut faire en sorte que ce thread abaisse sa priorité et fasse lui-même explicitement appel régulièrement à un re-scheduling du système (Fair share !).}
						\eitem
			\section{Autres solutions}
				\subsection{LightWeight Profiling}
					Pour palier au majeur problème que pose l'utilisation d'\IBS, c'est-à-dire, le surcoût d'éxécution (overhead), AMD a élaboré un nouveau système de profiling se basant sur les mêmes principes qu'\IBS mais permettant une réduction significative du surcoût d'éxécution induit par les mesures. Le second argument majeur de cette technique est qu'elle peut être totalement controlée en mode utilisateur, sans à aucun moment avoir besoin d'interagir directement avec le noyau.\\
					Le principe reste donc similaire, tagger aléatoirement des instructions durant l'éxécution d'un coeur pour ensuite suivre les effets produits par son éxécution, la différence du \lwp est qu'il va utiliser un tampon dans lequel il va insérer tous les résultats de ses mesures. Ensuite, régulièrement, un handler de traitement va être appelé pour traiter les résultats stockés dans le tampon. Le procédé permet ainsi facilement d'augmenter le taux d'échantillonage des mesures sans pour autant ralentir considérablement le système.\\
					Il y a deux modes de gestion de ce buffer, soit \lwp le rempli et lorsque celui-ci est plein, le handler est appelé, il doit alors récupérer et traiter les mesures, puis effacer le buffer pour faire place aux mesures suivantes (synchronized mode), soit \lwp rempli le buffer et appelle régulièrement le handler pour qu'il traite les données. Arrivé a la fin du buffer, \lwp recommencera à le remplir en partant du début, si les résultats n'ont pas été récupérés, il seront effacés.\\
					AMD définit donc sa propre structure de données pour stocker les résultats de ses opérations et fournit des fonctions de controle sur cette structure pour un plus grand confort d'utilisation.
